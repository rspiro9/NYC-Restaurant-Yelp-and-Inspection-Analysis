{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Model - Hypothesis Testing\n",
    "Now that we have explored our data (in notebook #1), let's begin to answer our key questions using hypothesis testing. Hypothesis testing is often used in order to determine whether or not an outcome is statistically significant. The key questions we will be evaluating are:  \n",
    "\n",
    "1. Does a restaurant's Yelp rating influence how many Yelp reviews the restaurant will receive?\n",
    "2. Does a restaurant's inspection grade influence how many Yelp reviews the restaurant will receive?\n",
    "3. Does the type of cuisine influence how many Yelp reviews the restaurant will receive?\n",
    "4. Is there a relationship between the Inspection Grade and the Neighborhood, Price, or Cuisine Type?\n",
    "\n",
    "\n",
    "We are looking into these question in order to help restaurateurs have a better understanding of things they can do to help gain more Yelp reviews or better inspection grades. Having more reviews (if positive) and having a better inspection grade could help elevate a restaurant and influence more people to go in and try a certain restaurant, therefore boosting revenue for that restaurant.\n",
    "\n",
    "First, we will call all needed libraries and import the dataset that we scrubbed in our EDA notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "# Import relevant libraries for hypothesis testing:\n",
    "from scipy import stats # for significance levels and normality\n",
    "import statsmodels.api as sm # for statistical exploration/testing\n",
    "from statsmodels.formula.api import ols # for hypothesis testing\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd # for pairwise comparisons\n",
    "from statsmodels.stats.multicomp import MultiComparison # for multiple comparisons testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3930\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CAMIS</th>\n",
       "      <th>DBA</th>\n",
       "      <th>BORO</th>\n",
       "      <th>BUILDING</th>\n",
       "      <th>STREET</th>\n",
       "      <th>ZIPCODE</th>\n",
       "      <th>display_phone</th>\n",
       "      <th>CUISINE DESCRIPTION</th>\n",
       "      <th>INSPECTION DATE</th>\n",
       "      <th>ACTION</th>\n",
       "      <th>...</th>\n",
       "      <th>wine_bars</th>\n",
       "      <th>womenscloth</th>\n",
       "      <th>wraps</th>\n",
       "      <th>delivery</th>\n",
       "      <th>pickup</th>\n",
       "      <th>restaurant_reservation</th>\n",
       "      <th>num_of_cat</th>\n",
       "      <th>mainstream_category</th>\n",
       "      <th>rare_category</th>\n",
       "      <th>price_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41322152</td>\n",
       "      <td>1 2 3 BURGER SHOT BEER</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>738</td>\n",
       "      <td>10 AVENUE</td>\n",
       "      <td>10019.0</td>\n",
       "      <td>(212) 315-0123</td>\n",
       "      <td>American</td>\n",
       "      <td>2019-12-20</td>\n",
       "      <td>Violations were cited in the following area(s).</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41430594</td>\n",
       "      <td>1 STOP PATTY SHOP</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>1708</td>\n",
       "      <td>AMSTERDAM AVENUE</td>\n",
       "      <td>10031.0</td>\n",
       "      <td>(212) 491-7466</td>\n",
       "      <td>Bakery</td>\n",
       "      <td>2019-03-27</td>\n",
       "      <td>Violations were cited in the following area(s).</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50059935</td>\n",
       "      <td>108 FOOD DRIED HOT POT</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>2794</td>\n",
       "      <td>BROADWAY</td>\n",
       "      <td>10025.0</td>\n",
       "      <td>(917) 675-6878</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>2019-05-23</td>\n",
       "      <td>Violations were cited in the following area(s).</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41092609</td>\n",
       "      <td>10TH AVENUE COOKSHOP</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>156</td>\n",
       "      <td>10 AVENUE</td>\n",
       "      <td>10011.0</td>\n",
       "      <td>(212) 924-4440</td>\n",
       "      <td>American</td>\n",
       "      <td>2019-04-11</td>\n",
       "      <td>Violations were cited in the following area(s).</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50057272</td>\n",
       "      <td>11 HANOVER GREEK</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>11</td>\n",
       "      <td>HANOVER SQ</td>\n",
       "      <td>10005.0</td>\n",
       "      <td>(212) 785-4000</td>\n",
       "      <td>Greek</td>\n",
       "      <td>2019-02-28</td>\n",
       "      <td>Violations were cited in the following area(s).</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 304 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CAMIS                     DBA       BORO BUILDING            STREET  \\\n",
       "0  41322152  1 2 3 BURGER SHOT BEER  Manhattan      738         10 AVENUE   \n",
       "1  41430594       1 STOP PATTY SHOP  Manhattan     1708  AMSTERDAM AVENUE   \n",
       "2  50059935  108 FOOD DRIED HOT POT  Manhattan     2794          BROADWAY   \n",
       "3  41092609    10TH AVENUE COOKSHOP  Manhattan      156         10 AVENUE   \n",
       "4  50057272        11 HANOVER GREEK  Manhattan       11        HANOVER SQ   \n",
       "\n",
       "   ZIPCODE   display_phone CUISINE DESCRIPTION INSPECTION DATE  \\\n",
       "0  10019.0  (212) 315-0123            American      2019-12-20   \n",
       "1  10031.0  (212) 491-7466              Bakery      2019-03-27   \n",
       "2  10025.0  (917) 675-6878             Chinese      2019-05-23   \n",
       "3  10011.0  (212) 924-4440            American      2019-04-11   \n",
       "4  10005.0  (212) 785-4000               Greek      2019-02-28   \n",
       "\n",
       "                                            ACTION     ...     wine_bars  \\\n",
       "0  Violations were cited in the following area(s).     ...             0   \n",
       "1  Violations were cited in the following area(s).     ...             0   \n",
       "2  Violations were cited in the following area(s).     ...             0   \n",
       "3  Violations were cited in the following area(s).     ...             1   \n",
       "4  Violations were cited in the following area(s).     ...             1   \n",
       "\n",
       "  womenscloth wraps delivery pickup  restaurant_reservation  num_of_cat  \\\n",
       "0           0     0        1      1                       0           3   \n",
       "1           0     0        0      0                       0           2   \n",
       "2           0     0        1      1                       0           2   \n",
       "3           0     0        1      1                       0           3   \n",
       "4           0     0        1      1                       0           3   \n",
       "\n",
       "   mainstream_category rare_category price_value  \n",
       "0                    1             0           1  \n",
       "1                    1             0           1  \n",
       "2                    1             0           2  \n",
       "3                    1             0           2  \n",
       "4                    1             0           3  \n",
       "\n",
       "[5 rows x 304 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Data:\n",
    "with open ('scrubbed_data.pickle','rb') as f:\n",
    "    df_merged = pickle.load(f)\n",
    "\n",
    "print(len(df_merged))\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Yelp Rating vs. # of Yelp Reviews\n",
    "\n",
    "I will begin by setting my hypothesis. The Null Hypothesis ( 𝐻0 ) is typically that there is no difference between the samples, while the Alternative Hypothesis ( 𝐻𝐴 ) is our educated guess about the relationship between our two samples. Below are the hypothesis I will be using to answer this first question:  \n",
    "\n",
    "**𝐻0  = There is no difference in the number of Yelp reviews received by restaurants with a high (4.0 or above) Yelp rating vs. a low (3.5 or below) Yelp rating.  \n",
    "𝐻𝐴  = The number of Yelp reviews received by restaurants with high ratings is statistically greater than the number of Yelp reviews received by restaurants with low Yelp ratings.**\n",
    "\n",
    "We will be using an alpha value of .05 to determine if our data is statistically significant. This means that we are fine with accepting our alternative hypothesis as true if there is less than a 5% chance the results we are getting are actually due to randomness.\n",
    "\n",
    "To begin our hypothesis testing, let's first group the data to identify high Yelp ratings (4+) and low Yelp ratings (3.5 and below). I then will take a look at the mean scores for the number of reviews  for high Yelp rating vs. low Yelp rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High Score Mean: 352.6193628465039\n",
      "Low Score Mean: 314.0522141440846\n"
     ]
    }
   ],
   "source": [
    "# Update rating to be grouped by high (4+) and low (3.5 and below) ratings:\n",
    "score = {1: 0, 1.5: 0, 2:0, 2.5: 0, 3: 0, 3.5:0,4:1,4.5:1,5:1}\n",
    "df_merged['rating_score'] = df_merged['rating'].map(score)\n",
    "\n",
    "# Select data needed for analysis:\n",
    "high_star = df_merged[df_merged['rating_score']==1]['review_count']\n",
    "low_star = df_merged[df_merged['rating_score']==0]['review_count']\n",
    "\n",
    "# Compare mean scores of number of review for high Yelp ratings vs. low Yelp ratings:\n",
    "print('High Score Mean:',high_star.mean())\n",
    "print('Low Score Mean:',low_star.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the mean values, it does seem like having a high rating may indicate more reviews have been written for a restaurant.  Next I will need to choose the appropriate testing method. We typically use a t-test for hypothesis testing, which tells us if there is a statistical difference between the means of two populations. If our sample sizes and/or sample variances are equal, then we would use a standard student's t-test. However, if sample size and variances are unequal between our 2 populations, then we should use an adaption of the student's t-test known as a Welch's t-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are variances equal?: False\n",
      "Are sample sizes equal?: False\n"
     ]
    }
   ],
   "source": [
    "# Test whether variances and sample size are equal:\n",
    "print('Are variances equal?:',np.var(high_star) == np.var(low_star))\n",
    "print('Are sample sizes equal?:',len(high_star) == len(low_star))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our sample sizes and variances are not equal, we will proceed with the Welch's t-test. We will use a 1-tailed t-test since we are just looking to see if a high rating leads to a greater number of reviews. I will use the ttest_ind function to determine if there is any difference in the number of reviews, and will pass the 'equal_var = False' function to indicate that our variances are unequal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reject Null Hypothesis\n",
      "t-statistic: 3.931521379542655 p-value: 4.302440410486111e-05\n"
     ]
    }
   ],
   "source": [
    "# Run 1-sided Welch's t-test:\n",
    "result = stats.ttest_ind(high_star, low_star, equal_var = False) # 1-tailed Welch's t-test\n",
    "print('Reject Null Hypothesis' if result[1]/2<.05 else print('Failed to Reject Null Hypothesis'))\n",
    "print('t-statistic:',result[0],'p-value:',result[1]/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We end up with a very low p-value that is less than our alpha value of .05. This value is statistically significant and gives a strong case against our null hypothesis. Therefore, we would reject our null hypothesis and say that having a high Yelp rating does lead to a greater number of reviews being written compared to restaurants with low ratings.  \n",
    "\n",
    "Let's now quantify the size of the difference between our 2 means by looking at the effect size.\n",
    "\n",
    "### Effect Size:\n",
    "Effect size will help us understand the practical significance of our results. In other words, how meaningful is the statistical difference between our two groups. To understand the effect size, I will use Cohen's d, which represents the magnitude of differences between 2 groups on a given variable. Larger values for Cohen's d will indicate greater differentiation between the two groups. A Cohen's d effect size around .2 is considered 'small', around .5 is considered 'medium, and around .8 is considered 'large'.\n",
    "\n",
    "The formula for Cohen's d is:\n",
    "𝑑 = effect size (difference of means) / pooled standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cohen's d formula:\n",
    "def Cohen_d(group1, group2):\n",
    "    '''This function takes in two groups of data and calculates the Cohen's d value between them.'''\n",
    "\n",
    "    diff = group1.mean() - group2.mean()\n",
    "\n",
    "    n1, n2 = len(group1), len(group2)\n",
    "    var1 = group1.var()\n",
    "    var2 = group2.var()\n",
    "\n",
    "    # Calculate the pooled threshold\n",
    "    pooled_var = (n1 * var1 + n2 * var2) / (n1 + n2)\n",
    "    \n",
    "    # Calculate Cohen's d statistic\n",
    "    d = diff / np.sqrt(pooled_var)\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1254212679098783"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run Cohen's d for our data:\n",
    "Cohen_d(high_star,low_star)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a low Cohen d value of .125, we can say having a high Yelp rating has only a small effect on the number of reviews.  \n",
    "\n",
    "## 4.2 Inspection Grade vs. # of Yelp Reviews\n",
    "Let's now run the same analysis looking at the relationship between inspection grades and # of Yelp reviews.\n",
    " \n",
    "**𝐻0  = There is no difference in the number of Yelp reviews received by restaurants with a high inspection grade (A)  vs. a low inspection grade (B or C).  \n",
    "𝐻𝐴  = The number of Yelp reviews received by restaurants with high inspection grades is statistically greater than the number of Yelp reviews received by restaurants with low inspection grades.**\n",
    "\n",
    "Let's first identify the data we will be using as either a high grade (A) or not a high grade (not an A)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High Grade Mean: 345.80331125827814\n",
      "Low Grade Mean: 309.01020408163265\n"
     ]
    }
   ],
   "source": [
    "# Select only data that has an actual inspection grade of A, B, or C.\n",
    "df_merged_temp = df_merged.loc[df_merged['GRADE'].isin(['A','B','C'])].copy()\n",
    "\n",
    "# Select data needed for analysis:\n",
    "high_grade = df_merged_temp[df_merged_temp['GRADE']=='A']['review_count']\n",
    "low_grade = df_merged_temp[df_merged_temp['GRADE']!='A']['review_count']\n",
    "\n",
    "# Compare mean scores of number of reviews for high Yelp ratings vs. low Yelp ratings:\n",
    "print('High Grade Mean:',high_grade.mean())\n",
    "print('Low Grade Mean:',low_grade.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean for having an A grade seems to be a bit higher than the mean for lower inspection grades. Let's move forward with the rest of our hypothesis testing by checking if the variances and sample sizes are equal or different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are variances equal?: False\n",
      "Are sample sizes equal?: False\n"
     ]
    }
   ],
   "source": [
    "# Test whether variances and sample size are equal:\n",
    "print('Are variances equal?:',np.var(high_grade) == np.var(low_grade))\n",
    "print('Are sample sizes equal?:',len(high_grade) == len(low_grade))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our sample sizes and variances are not equal, we will proceed with a 1 tailed Welch's t-test using an alpha value of .05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reject Null Hypothesis\n",
      "t-statistic: 1.6560018608590783 p-value: 0.049565266142070984\n"
     ]
    }
   ],
   "source": [
    "# Run 1-sided Welch's t-test:\n",
    "result2 = stats.ttest_ind(high_grade, low_grade, equal_var = False) # 1-tailed Welch's t-test\n",
    "print('Reject Null Hypothesis' if result2[1]/2<.05 else print('Failed to Reject Null Hypothesis'))\n",
    "print('t-statistic:',result2[0],'p-value:',result2[1]/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our p-value is just under the alpha value threshold of .05, so we can reject the null hypothesis here. Therefore, we can say that there is a meaningful relationship between the inspection grade given and the number of Yelp reviews present for a restaurant.\n",
    "\n",
    "Let's take a look at the effect size here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11917228221276982"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run Cohen's d for our data:\n",
    "Cohen_d(high_grade,low_grade)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a low Cohen's d score of .119, we can say there is a small effect size.\n",
    "\n",
    "## 4.3 Cusine Type vs. # of Yelp Reviews\n",
    "\n",
    "Let's take a look at the relationship between the type of cuisine and the number of Yelp reviews.\n",
    "\n",
    "**𝐻0  = There is no relationship between the cuisine type and the # of Yelp reivews.\n",
    "<br>𝐻𝐴  = There is at least one cuisine type with a significantly different number of Yelp reviews.<br>**\n",
    "\n",
    "We will use an ANOVA test here rather than a t-test since we are looking at multiple different groups (i.e. each cuisine is considered a different group). Similar to the t-tests used earlier, ANOVA will allow us to compare the means of each cuisine type to see if there are any statistical differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              sum_sq      df         F        PR(>F)\n",
      "C(CUISINE_DESCRIPTION)  2.588763e+07    74.0  3.887362  1.035454e-25\n",
      "Residual                3.469205e+08  3855.0       NaN           NaN\n"
     ]
    }
   ],
   "source": [
    "# Re-name the cuisine description column to have no spaces so that we can run it through the anova test.\n",
    "df_merged.rename(columns={'CUISINE DESCRIPTION': 'CUISINE_DESCRIPTION'}, inplace=True)\n",
    "\n",
    "# Perform 2-sided ANOVA test. Use C() when working with categorical data\n",
    "formula1 = 'review_count ~ C(CUISINE_DESCRIPTION)'\n",
    "lm1 = ols(formula1, df_merged).fit()\n",
    "result1 = sm.stats.anova_lm(lm1, typ=2)\n",
    "print(result1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a very low p-value that is much smaller than our alpha of .05. Therefore, we can reject our null hypothesis.  \n",
    "\n",
    "This ANOVA test only tells us that at least one of the cuisines signficantly differs from one (or multiple) other cuisines. While this is helpful to know, it would be even more helpful to know which cuisines are generating statistically high number of reviews, and which (if any) are similar to each other. To do this, we can perform a multiple comparisons analysis, which will compare all possible pairwise groups of means, and use Tukey's HSD test to determine the statistical significance of these comparisons. Since there are over 200 cuisine types, I will just show the rows of the Tukey results that reject the null hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group1</th>\n",
       "      <th>group2</th>\n",
       "      <th>meandiff</th>\n",
       "      <th>p-adj</th>\n",
       "      <th>lower</th>\n",
       "      <th>upper</th>\n",
       "      <th>reject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>American</td>\n",
       "      <td>Chicken</td>\n",
       "      <td>-190.9560</td>\n",
       "      <td>0.0457</td>\n",
       "      <td>-380.7624</td>\n",
       "      <td>-1.1496</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>American</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>-100.9642</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>-184.4225</td>\n",
       "      <td>-17.5058</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>American</td>\n",
       "      <td>Other</td>\n",
       "      <td>-193.6060</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>-340.2303</td>\n",
       "      <td>-46.9818</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>American</td>\n",
       "      <td>Pizza</td>\n",
       "      <td>-126.8779</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>-245.7389</td>\n",
       "      <td>-8.0169</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>Barbecue</td>\n",
       "      <td>Chicken</td>\n",
       "      <td>-389.7667</td>\n",
       "      <td>0.0241</td>\n",
       "      <td>-762.6087</td>\n",
       "      <td>-16.9247</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>Barbecue</td>\n",
       "      <td>Other</td>\n",
       "      <td>-392.4167</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>-745.2386</td>\n",
       "      <td>-39.5947</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>Barbecue</td>\n",
       "      <td>Salads</td>\n",
       "      <td>-410.4542</td>\n",
       "      <td>0.0238</td>\n",
       "      <td>-802.8395</td>\n",
       "      <td>-18.0688</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>Barbecue</td>\n",
       "      <td>Sandwiches</td>\n",
       "      <td>-430.3101</td>\n",
       "      <td>0.0292</td>\n",
       "      <td>-846.4762</td>\n",
       "      <td>-14.1441</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>Café/Coffee/Tea</td>\n",
       "      <td>French</td>\n",
       "      <td>190.2045</td>\n",
       "      <td>0.0419</td>\n",
       "      <td>2.2071</td>\n",
       "      <td>378.2019</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>Café/Coffee/Tea</td>\n",
       "      <td>Italian</td>\n",
       "      <td>177.7321</td>\n",
       "      <td>0.0192</td>\n",
       "      <td>9.9171</td>\n",
       "      <td>345.5470</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>Café/Coffee/Tea</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>179.9603</td>\n",
       "      <td>0.0242</td>\n",
       "      <td>7.7660</td>\n",
       "      <td>352.1546</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>Café/Coffee/Tea</td>\n",
       "      <td>Korean</td>\n",
       "      <td>308.6466</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>93.3843</td>\n",
       "      <td>523.9089</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>Café/Coffee/Tea</td>\n",
       "      <td>Seafood</td>\n",
       "      <td>244.2777</td>\n",
       "      <td>0.0137</td>\n",
       "      <td>17.7787</td>\n",
       "      <td>470.7767</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>Café/Coffee/Tea</td>\n",
       "      <td>Steak</td>\n",
       "      <td>278.7624</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>35.5880</td>\n",
       "      <td>521.9368</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1075</th>\n",
       "      <td>Chicken</td>\n",
       "      <td>French</td>\n",
       "      <td>225.7199</td>\n",
       "      <td>0.0188</td>\n",
       "      <td>12.7997</td>\n",
       "      <td>438.6400</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>Chicken</td>\n",
       "      <td>Italian</td>\n",
       "      <td>213.2475</td>\n",
       "      <td>0.0108</td>\n",
       "      <td>17.9174</td>\n",
       "      <td>408.5775</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1087</th>\n",
       "      <td>Chicken</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>215.4757</td>\n",
       "      <td>0.0128</td>\n",
       "      <td>16.3705</td>\n",
       "      <td>414.5809</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090</th>\n",
       "      <td>Chicken</td>\n",
       "      <td>Korean</td>\n",
       "      <td>344.1620</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>106.8229</td>\n",
       "      <td>581.5011</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>Chicken</td>\n",
       "      <td>Seafood</td>\n",
       "      <td>279.7931</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>32.2173</td>\n",
       "      <td>527.3689</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1115</th>\n",
       "      <td>Chicken</td>\n",
       "      <td>Steak</td>\n",
       "      <td>314.2778</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>51.3600</td>\n",
       "      <td>577.1956</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1120</th>\n",
       "      <td>Chicken</td>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>275.8684</td>\n",
       "      <td>0.0474</td>\n",
       "      <td>0.9819</td>\n",
       "      <td>550.7549</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1132</th>\n",
       "      <td>Chinese</td>\n",
       "      <td>French</td>\n",
       "      <td>135.7280</td>\n",
       "      <td>0.0176</td>\n",
       "      <td>8.1591</td>\n",
       "      <td>263.2969</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1143</th>\n",
       "      <td>Chinese</td>\n",
       "      <td>Italian</td>\n",
       "      <td>123.2556</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>27.9002</td>\n",
       "      <td>218.6110</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144</th>\n",
       "      <td>Chinese</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>125.4838</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>22.6165</td>\n",
       "      <td>228.3512</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1147</th>\n",
       "      <td>Chinese</td>\n",
       "      <td>Korean</td>\n",
       "      <td>254.1701</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>89.0378</td>\n",
       "      <td>419.3024</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1167</th>\n",
       "      <td>Chinese</td>\n",
       "      <td>Seafood</td>\n",
       "      <td>189.8012</td>\n",
       "      <td>0.0198</td>\n",
       "      <td>10.2668</td>\n",
       "      <td>369.3357</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1172</th>\n",
       "      <td>Chinese</td>\n",
       "      <td>Steak</td>\n",
       "      <td>224.2859</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>24.1245</td>\n",
       "      <td>424.4473</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1365</th>\n",
       "      <td>Delicatessen</td>\n",
       "      <td>Korean</td>\n",
       "      <td>326.4239</td>\n",
       "      <td>0.0231</td>\n",
       "      <td>14.9372</td>\n",
       "      <td>637.9106</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1716</th>\n",
       "      <td>French</td>\n",
       "      <td>Other</td>\n",
       "      <td>-228.3699</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>-403.8896</td>\n",
       "      <td>-52.8501</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1719</th>\n",
       "      <td>French</td>\n",
       "      <td>Pizza</td>\n",
       "      <td>-161.6417</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>-314.7315</td>\n",
       "      <td>-8.5520</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1724</th>\n",
       "      <td>French</td>\n",
       "      <td>Salads</td>\n",
       "      <td>-246.4074</td>\n",
       "      <td>0.0475</td>\n",
       "      <td>-491.9478</td>\n",
       "      <td>-0.8670</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1882</th>\n",
       "      <td>Hawaiian</td>\n",
       "      <td>Korean</td>\n",
       "      <td>363.3620</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>45.9225</td>\n",
       "      <td>680.8015</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>Indian</td>\n",
       "      <td>Other</td>\n",
       "      <td>-206.3167</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>-396.1446</td>\n",
       "      <td>-16.4887</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2113</th>\n",
       "      <td>Irish</td>\n",
       "      <td>Korean</td>\n",
       "      <td>249.2220</td>\n",
       "      <td>0.0141</td>\n",
       "      <td>17.7156</td>\n",
       "      <td>480.7283</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2156</th>\n",
       "      <td>Italian</td>\n",
       "      <td>Other</td>\n",
       "      <td>-215.8975</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>-369.6051</td>\n",
       "      <td>-62.1899</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2159</th>\n",
       "      <td>Italian</td>\n",
       "      <td>Pizza</td>\n",
       "      <td>-149.1693</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>-276.6656</td>\n",
       "      <td>-21.6731</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2164</th>\n",
       "      <td>Italian</td>\n",
       "      <td>Salads</td>\n",
       "      <td>-233.9350</td>\n",
       "      <td>0.0397</td>\n",
       "      <td>-464.3887</td>\n",
       "      <td>-3.4812</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2190</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>Other</td>\n",
       "      <td>-218.1257</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>-376.6030</td>\n",
       "      <td>-59.6484</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2193</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>Pizza</td>\n",
       "      <td>-151.3976</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>-284.6054</td>\n",
       "      <td>-18.1897</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2198</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>Salads</td>\n",
       "      <td>-236.1632</td>\n",
       "      <td>0.0425</td>\n",
       "      <td>-469.8253</td>\n",
       "      <td>-2.5011</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2280</th>\n",
       "      <td>Korean</td>\n",
       "      <td>Mediterranean</td>\n",
       "      <td>-196.4296</td>\n",
       "      <td>0.0448</td>\n",
       "      <td>-391.4420</td>\n",
       "      <td>-1.4173</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2286</th>\n",
       "      <td>Korean</td>\n",
       "      <td>Other</td>\n",
       "      <td>-346.8120</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>-551.2674</td>\n",
       "      <td>-142.3565</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2289</th>\n",
       "      <td>Korean</td>\n",
       "      <td>Pizza</td>\n",
       "      <td>-280.0838</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>-465.6406</td>\n",
       "      <td>-94.5271</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2290</th>\n",
       "      <td>Korean</td>\n",
       "      <td>Pizza/Italian</td>\n",
       "      <td>-229.8112</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>-443.3897</td>\n",
       "      <td>-16.2328</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2294</th>\n",
       "      <td>Korean</td>\n",
       "      <td>Salads</td>\n",
       "      <td>-364.8495</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>-631.8419</td>\n",
       "      <td>-97.8571</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2295</th>\n",
       "      <td>Korean</td>\n",
       "      <td>Sandwiches</td>\n",
       "      <td>-384.7055</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>-685.5591</td>\n",
       "      <td>-83.8518</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2373</th>\n",
       "      <td>Mexican</td>\n",
       "      <td>Other</td>\n",
       "      <td>-176.8874</td>\n",
       "      <td>0.0228</td>\n",
       "      <td>-345.5283</td>\n",
       "      <td>-8.2466</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2510</th>\n",
       "      <td>Other</td>\n",
       "      <td>Seafood</td>\n",
       "      <td>282.4431</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>66.1887</td>\n",
       "      <td>498.6975</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2515</th>\n",
       "      <td>Other</td>\n",
       "      <td>Steak</td>\n",
       "      <td>316.9278</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>83.2657</td>\n",
       "      <td>550.5898</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2518</th>\n",
       "      <td>Other</td>\n",
       "      <td>Thai</td>\n",
       "      <td>197.5745</td>\n",
       "      <td>0.0177</td>\n",
       "      <td>11.8612</td>\n",
       "      <td>383.2878</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2520</th>\n",
       "      <td>Other</td>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>278.5184</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>31.4663</td>\n",
       "      <td>525.5706</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2521</th>\n",
       "      <td>Other</td>\n",
       "      <td>Vietnamese/Cambodian/Malaysia</td>\n",
       "      <td>264.7438</td>\n",
       "      <td>0.0434</td>\n",
       "      <td>2.4587</td>\n",
       "      <td>527.0288</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2573</th>\n",
       "      <td>Pizza</td>\n",
       "      <td>Seafood</td>\n",
       "      <td>215.7150</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>17.2326</td>\n",
       "      <td>414.1973</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2578</th>\n",
       "      <td>Pizza</td>\n",
       "      <td>Steak</td>\n",
       "      <td>250.1997</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>32.8814</td>\n",
       "      <td>467.5179</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2658</th>\n",
       "      <td>Salads</td>\n",
       "      <td>Seafood</td>\n",
       "      <td>300.4806</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>24.3486</td>\n",
       "      <td>576.6126</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2663</th>\n",
       "      <td>Salads</td>\n",
       "      <td>Steak</td>\n",
       "      <td>334.9653</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>44.9983</td>\n",
       "      <td>624.9323</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2672</th>\n",
       "      <td>Sandwiches</td>\n",
       "      <td>Seafood</td>\n",
       "      <td>320.3366</td>\n",
       "      <td>0.0279</td>\n",
       "      <td>11.3433</td>\n",
       "      <td>629.3299</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2677</th>\n",
       "      <td>Sandwiches</td>\n",
       "      <td>Steak</td>\n",
       "      <td>354.8213</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>33.4043</td>\n",
       "      <td>676.2382</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               group1                         group2  meandiff   p-adj  \\\n",
       "160          American                        Chicken -190.9560  0.0457   \n",
       "161          American                        Chinese -100.9642  0.0011   \n",
       "195          American                          Other -193.6060  0.0010   \n",
       "198          American                          Pizza -126.8779  0.0166   \n",
       "636          Barbecue                        Chicken -389.7667  0.0241   \n",
       "671          Barbecue                          Other -392.4167  0.0074   \n",
       "679          Barbecue                         Salads -410.4542  0.0238   \n",
       "680          Barbecue                     Sandwiches -430.3101  0.0292   \n",
       "898   Café/Coffee/Tea                         French  190.2045  0.0419   \n",
       "909   Café/Coffee/Tea                        Italian  177.7321  0.0192   \n",
       "910   Café/Coffee/Tea                       Japanese  179.9603  0.0242   \n",
       "913   Café/Coffee/Tea                         Korean  308.6466  0.0010   \n",
       "933   Café/Coffee/Tea                        Seafood  244.2777  0.0137   \n",
       "938   Café/Coffee/Tea                          Steak  278.7624  0.0039   \n",
       "1075          Chicken                         French  225.7199  0.0188   \n",
       "1086          Chicken                        Italian  213.2475  0.0108   \n",
       "1087          Chicken                       Japanese  215.4757  0.0128   \n",
       "1090          Chicken                         Korean  344.1620  0.0010   \n",
       "1110          Chicken                        Seafood  279.7931  0.0053   \n",
       "1115          Chicken                          Steak  314.2778  0.0014   \n",
       "1120          Chicken                     Vegetarian  275.8684  0.0474   \n",
       "1132          Chinese                         French  135.7280  0.0176   \n",
       "1143          Chinese                        Italian  123.2556  0.0010   \n",
       "1144          Chinese                       Japanese  125.4838  0.0010   \n",
       "1147          Chinese                         Korean  254.1701  0.0010   \n",
       "1167          Chinese                        Seafood  189.8012  0.0198   \n",
       "1172          Chinese                          Steak  224.2859  0.0063   \n",
       "1365     Delicatessen                         Korean  326.4239  0.0231   \n",
       "1716           French                          Other -228.3699  0.0010   \n",
       "1719           French                          Pizza -161.6417  0.0202   \n",
       "1724           French                         Salads -246.4074  0.0475   \n",
       "1882         Hawaiian                         Korean  363.3620  0.0040   \n",
       "2010           Indian                          Other -206.3167  0.0118   \n",
       "2113            Irish                         Korean  249.2220  0.0141   \n",
       "2156          Italian                          Other -215.8975  0.0010   \n",
       "2159          Italian                          Pizza -149.1693  0.0024   \n",
       "2164          Italian                         Salads -233.9350  0.0397   \n",
       "2190         Japanese                          Other -218.1257  0.0010   \n",
       "2193         Japanese                          Pizza -151.3976  0.0047   \n",
       "2198         Japanese                         Salads -236.1632  0.0425   \n",
       "2280           Korean                  Mediterranean -196.4296  0.0448   \n",
       "2286           Korean                          Other -346.8120  0.0010   \n",
       "2289           Korean                          Pizza -280.0838  0.0010   \n",
       "2290           Korean                  Pizza/Italian -229.8112  0.0143   \n",
       "2294           Korean                         Salads -364.8495  0.0010   \n",
       "2295           Korean                     Sandwiches -384.7055  0.0010   \n",
       "2373          Mexican                          Other -176.8874  0.0228   \n",
       "2510            Other                        Seafood  282.4431  0.0010   \n",
       "2515            Other                          Steak  316.9278  0.0010   \n",
       "2518            Other                           Thai  197.5745  0.0177   \n",
       "2520            Other                     Vegetarian  278.5184  0.0056   \n",
       "2521            Other  Vietnamese/Cambodian/Malaysia  264.7438  0.0434   \n",
       "2573            Pizza                        Seafood  215.7150  0.0118   \n",
       "2578            Pizza                          Steak  250.1997  0.0035   \n",
       "2658           Salads                        Seafood  300.4806  0.0115   \n",
       "2663           Salads                          Steak  334.9653  0.0032   \n",
       "2672       Sandwiches                        Seafood  320.3366  0.0279   \n",
       "2677       Sandwiches                          Steak  354.8213  0.0086   \n",
       "\n",
       "         lower     upper  reject  \n",
       "160  -380.7624   -1.1496    True  \n",
       "161  -184.4225  -17.5058    True  \n",
       "195  -340.2303  -46.9818    True  \n",
       "198  -245.7389   -8.0169    True  \n",
       "636  -762.6087  -16.9247    True  \n",
       "671  -745.2386  -39.5947    True  \n",
       "679  -802.8395  -18.0688    True  \n",
       "680  -846.4762  -14.1441    True  \n",
       "898     2.2071  378.2019    True  \n",
       "909     9.9171  345.5470    True  \n",
       "910     7.7660  352.1546    True  \n",
       "913    93.3843  523.9089    True  \n",
       "933    17.7787  470.7767    True  \n",
       "938    35.5880  521.9368    True  \n",
       "1075   12.7997  438.6400    True  \n",
       "1086   17.9174  408.5775    True  \n",
       "1087   16.3705  414.5809    True  \n",
       "1090  106.8229  581.5011    True  \n",
       "1110   32.2173  527.3689    True  \n",
       "1115   51.3600  577.1956    True  \n",
       "1120    0.9819  550.7549    True  \n",
       "1132    8.1591  263.2969    True  \n",
       "1143   27.9002  218.6110    True  \n",
       "1144   22.6165  228.3512    True  \n",
       "1147   89.0378  419.3024    True  \n",
       "1167   10.2668  369.3357    True  \n",
       "1172   24.1245  424.4473    True  \n",
       "1365   14.9372  637.9106    True  \n",
       "1716 -403.8896  -52.8501    True  \n",
       "1719 -314.7315   -8.5520    True  \n",
       "1724 -491.9478   -0.8670    True  \n",
       "1882   45.9225  680.8015    True  \n",
       "2010 -396.1446  -16.4887    True  \n",
       "2113   17.7156  480.7283    True  \n",
       "2156 -369.6051  -62.1899    True  \n",
       "2159 -276.6656  -21.6731    True  \n",
       "2164 -464.3887   -3.4812    True  \n",
       "2190 -376.6030  -59.6484    True  \n",
       "2193 -284.6054  -18.1897    True  \n",
       "2198 -469.8253   -2.5011    True  \n",
       "2280 -391.4420   -1.4173    True  \n",
       "2286 -551.2674 -142.3565    True  \n",
       "2289 -465.6406  -94.5271    True  \n",
       "2290 -443.3897  -16.2328    True  \n",
       "2294 -631.8419  -97.8571    True  \n",
       "2295 -685.5591  -83.8518    True  \n",
       "2373 -345.5283   -8.2466    True  \n",
       "2510   66.1887  498.6975    True  \n",
       "2515   83.2657  550.5898    True  \n",
       "2518   11.8612  383.2878    True  \n",
       "2520   31.4663  525.5706    True  \n",
       "2521    2.4587  527.0288    True  \n",
       "2573   17.2326  414.1973    True  \n",
       "2578   32.8814  467.5179    True  \n",
       "2658   24.3486  576.6126    True  \n",
       "2663   44.9983  624.9323    True  \n",
       "2672   11.3433  629.3299    True  \n",
       "2677   33.4043  676.2382    True  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform Tukey's HSD Test:\n",
    "mc1 = MultiComparison(df_merged['review_count'], df_merged['CUISINE_DESCRIPTION'])\n",
    "mc1_results = mc1.tukeyhsd()\n",
    "\n",
    "# Convert results to a dataframe:\n",
    "tukey_data1 = pd.DataFrame(data=mc1_results._results_table.data[1:], columns = mc1_results._results_table.data[0])\n",
    "\n",
    "# Select only rows where we are rejecting the null hypothesis:\n",
    "tukey_data1 = tukey_data1.loc[tukey_data1['reject']==True]\n",
    "tukey_data1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a lot of statistical significances here. We can utilize the meandiff column above to determine which of the two groups has a higher mean for each combination of cuisines. Next, I will create a function that allows us to take a look at the effect size of each of those pairings that are statisitcally significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's d Chart:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cuisine1</th>\n",
       "      <th>Cuisine2</th>\n",
       "      <th>Cohen's d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>American</td>\n",
       "      <td>Chicken</td>\n",
       "      <td>0.615966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>American</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>0.326166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>American</td>\n",
       "      <td>Other</td>\n",
       "      <td>0.630111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>American</td>\n",
       "      <td>Pizza</td>\n",
       "      <td>0.409269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Barbecue</td>\n",
       "      <td>Chicken</td>\n",
       "      <td>1.441044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Barbecue</td>\n",
       "      <td>Other</td>\n",
       "      <td>1.543021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Barbecue</td>\n",
       "      <td>Salads</td>\n",
       "      <td>1.791140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Barbecue</td>\n",
       "      <td>Sandwiches</td>\n",
       "      <td>1.612540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Café/Coffee/Tea</td>\n",
       "      <td>French</td>\n",
       "      <td>-0.663250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Café/Coffee/Tea</td>\n",
       "      <td>Italian</td>\n",
       "      <td>-0.632607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Café/Coffee/Tea</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>-0.577608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Café/Coffee/Tea</td>\n",
       "      <td>Korean</td>\n",
       "      <td>-1.010992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Café/Coffee/Tea</td>\n",
       "      <td>Seafood</td>\n",
       "      <td>-0.782859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Café/Coffee/Tea</td>\n",
       "      <td>Steak</td>\n",
       "      <td>-0.982271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Chicken</td>\n",
       "      <td>French</td>\n",
       "      <td>-0.783509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Chicken</td>\n",
       "      <td>Italian</td>\n",
       "      <td>-0.758169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Chicken</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>-0.687134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Chicken</td>\n",
       "      <td>Korean</td>\n",
       "      <td>-1.109692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Chicken</td>\n",
       "      <td>Seafood</td>\n",
       "      <td>-0.878293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Chicken</td>\n",
       "      <td>Steak</td>\n",
       "      <td>-1.099294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Chicken</td>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>-0.998954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Chinese</td>\n",
       "      <td>French</td>\n",
       "      <td>-0.452697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Chinese</td>\n",
       "      <td>Italian</td>\n",
       "      <td>-0.422891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Chinese</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>-0.403320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Chinese</td>\n",
       "      <td>Korean</td>\n",
       "      <td>-0.823539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Chinese</td>\n",
       "      <td>Seafood</td>\n",
       "      <td>-0.610268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Chinese</td>\n",
       "      <td>Steak</td>\n",
       "      <td>-0.741679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Delicatessen</td>\n",
       "      <td>Korean</td>\n",
       "      <td>-0.959025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>French</td>\n",
       "      <td>Other</td>\n",
       "      <td>0.818555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>French</td>\n",
       "      <td>Pizza</td>\n",
       "      <td>0.548038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>French</td>\n",
       "      <td>Salads</td>\n",
       "      <td>0.881248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Hawaiian</td>\n",
       "      <td>Korean</td>\n",
       "      <td>-1.092668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Indian</td>\n",
       "      <td>Other</td>\n",
       "      <td>0.837152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Irish</td>\n",
       "      <td>Korean</td>\n",
       "      <td>-0.865685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Italian</td>\n",
       "      <td>Other</td>\n",
       "      <td>0.778075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Italian</td>\n",
       "      <td>Pizza</td>\n",
       "      <td>0.521651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Italian</td>\n",
       "      <td>Salads</td>\n",
       "      <td>0.842832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>Other</td>\n",
       "      <td>0.712126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>Pizza</td>\n",
       "      <td>0.483874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>Salads</td>\n",
       "      <td>0.760607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Korean</td>\n",
       "      <td>Mediterranean</td>\n",
       "      <td>0.638302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Korean</td>\n",
       "      <td>Other</td>\n",
       "      <td>1.184913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Korean</td>\n",
       "      <td>Pizza</td>\n",
       "      <td>0.903232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Korean</td>\n",
       "      <td>Pizza/Italian</td>\n",
       "      <td>0.706556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Korean</td>\n",
       "      <td>Salads</td>\n",
       "      <td>1.216850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Korean</td>\n",
       "      <td>Sandwiches</td>\n",
       "      <td>1.210290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Mexican</td>\n",
       "      <td>Other</td>\n",
       "      <td>0.640059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Other</td>\n",
       "      <td>Seafood</td>\n",
       "      <td>-0.948527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Other</td>\n",
       "      <td>Steak</td>\n",
       "      <td>-1.173356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Other</td>\n",
       "      <td>Thai</td>\n",
       "      <td>-0.689587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Other</td>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>-1.063846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Other</td>\n",
       "      <td>Vietnamese/Cambodian/Malaysia</td>\n",
       "      <td>-1.048697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Pizza</td>\n",
       "      <td>Seafood</td>\n",
       "      <td>-0.685189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Pizza</td>\n",
       "      <td>Steak</td>\n",
       "      <td>-0.840808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Salads</td>\n",
       "      <td>Seafood</td>\n",
       "      <td>-0.974327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Salads</td>\n",
       "      <td>Steak</td>\n",
       "      <td>-1.259836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Sandwiches</td>\n",
       "      <td>Seafood</td>\n",
       "      <td>-0.971995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Sandwiches</td>\n",
       "      <td>Steak</td>\n",
       "      <td>-1.227568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Cuisine1                       Cuisine2  Cohen's d\n",
       "0          American                        Chicken   0.615966\n",
       "1          American                        Chinese   0.326166\n",
       "2          American                          Other   0.630111\n",
       "3          American                          Pizza   0.409269\n",
       "4          Barbecue                        Chicken   1.441044\n",
       "5          Barbecue                          Other   1.543021\n",
       "6          Barbecue                         Salads   1.791140\n",
       "7          Barbecue                     Sandwiches   1.612540\n",
       "8   Café/Coffee/Tea                         French  -0.663250\n",
       "9   Café/Coffee/Tea                        Italian  -0.632607\n",
       "10  Café/Coffee/Tea                       Japanese  -0.577608\n",
       "11  Café/Coffee/Tea                         Korean  -1.010992\n",
       "12  Café/Coffee/Tea                        Seafood  -0.782859\n",
       "13  Café/Coffee/Tea                          Steak  -0.982271\n",
       "14          Chicken                         French  -0.783509\n",
       "15          Chicken                        Italian  -0.758169\n",
       "16          Chicken                       Japanese  -0.687134\n",
       "17          Chicken                         Korean  -1.109692\n",
       "18          Chicken                        Seafood  -0.878293\n",
       "19          Chicken                          Steak  -1.099294\n",
       "20          Chicken                     Vegetarian  -0.998954\n",
       "21          Chinese                         French  -0.452697\n",
       "22          Chinese                        Italian  -0.422891\n",
       "23          Chinese                       Japanese  -0.403320\n",
       "24          Chinese                         Korean  -0.823539\n",
       "25          Chinese                        Seafood  -0.610268\n",
       "26          Chinese                          Steak  -0.741679\n",
       "27     Delicatessen                         Korean  -0.959025\n",
       "28           French                          Other   0.818555\n",
       "29           French                          Pizza   0.548038\n",
       "30           French                         Salads   0.881248\n",
       "31         Hawaiian                         Korean  -1.092668\n",
       "32           Indian                          Other   0.837152\n",
       "33            Irish                         Korean  -0.865685\n",
       "34          Italian                          Other   0.778075\n",
       "35          Italian                          Pizza   0.521651\n",
       "36          Italian                         Salads   0.842832\n",
       "37         Japanese                          Other   0.712126\n",
       "38         Japanese                          Pizza   0.483874\n",
       "39         Japanese                         Salads   0.760607\n",
       "40           Korean                  Mediterranean   0.638302\n",
       "41           Korean                          Other   1.184913\n",
       "42           Korean                          Pizza   0.903232\n",
       "43           Korean                  Pizza/Italian   0.706556\n",
       "44           Korean                         Salads   1.216850\n",
       "45           Korean                     Sandwiches   1.210290\n",
       "46          Mexican                          Other   0.640059\n",
       "47            Other                        Seafood  -0.948527\n",
       "48            Other                          Steak  -1.173356\n",
       "49            Other                           Thai  -0.689587\n",
       "50            Other                     Vegetarian  -1.063846\n",
       "51            Other  Vietnamese/Cambodian/Malaysia  -1.048697\n",
       "52            Pizza                        Seafood  -0.685189\n",
       "53            Pizza                          Steak  -0.840808\n",
       "54           Salads                        Seafood  -0.974327\n",
       "55           Salads                          Steak  -1.259836\n",
       "56       Sandwiches                        Seafood  -0.971995\n",
       "57       Sandwiches                          Steak  -1.227568"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a function to iterate through all of our desired combinations and find the cohen's d of each combination:\n",
    "def multi_cohen_d(values_list, data_column, value, column_label1, column_label2):\n",
    "    '''This function will evaluate Cohen's d between multiple identified pairs of data.\n",
    "    Inputs:\n",
    "        - values_list: list containing lists of each pair of values to evaluate\n",
    "        - data_column: column from full dataset that is used to match with the data in values_list \n",
    "        - value: column from full dataset that includes the actual data values you want to extract\n",
    "        - column_label1: label for the column of the dataframe we are creating that includes group1\n",
    "        - column_label2: label for the column of the dataframe we are creating that includes group2\n",
    "    \n",
    "    Returns:\n",
    "        - A dataframe listing the components of each group and the corresponding Cohen's d'''\n",
    "    \n",
    "    d = pd.DataFrame(columns = [column_label1,column_label2,\"Cohen's d\"], index = None)\n",
    "    for x in values_list:\n",
    "        cohen = Cohen_d(df_merged[df_merged[data_column]==x[0]][value],\n",
    "                        df_merged[df_merged[data_column]==x[1]][value])\n",
    "        d = d.append({column_label1:x[0],column_label2:x[1], \"Cohen's d\":cohen}, ignore_index=True)\n",
    "    return d\n",
    "\n",
    "# Identify the values we want to utilize to find Cohen's d:\n",
    "cuisine_list = tukey_data1.loc[tukey_data1['reject']==True].iloc[:,:2].values.tolist()\n",
    "\n",
    "# Run function to see all Cohen's d values:\n",
    "print(\"Cohen's d Chart:\")\n",
    "multi_cohen_d(cuisine_list, 'CUISINE_DESCRIPTION', 'review_count','Cuisine1', 'Cuisine2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like we have a variety of effect sizes here, with some being small, some being medium, and some being large.\n",
    "\n",
    "## 4.4 Inspection Grade vs. Neighborhood, Price, and Cuisine Type\n",
    "\n",
    "Let's now run an analysis looking at the relationship between inspection grades (using the SCORE column which gives the actual number grade that the grade represents) and the neighborhood, price, and type of cuisine for restaurants.\n",
    " \n",
    "**𝐻0  = There is no relationship between the inspection grade and the neighborhood, price, and cuisine type.\n",
    "<br>𝐻𝐴  = There is a relationship between the inspection grade and the neighborhood, price, and cuisine type.<br>**\n",
    "\n",
    "\n",
    "The first thing we need to do is remove any values in the SCORE column that are not numerical. We do this because our analysis will only run with numerical data for our target variable (the SCORE column). We'll also update the data type of the SCORE column to ensure it is numerical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with 'PEND' values so we only have restaurants with a numerical score:\n",
    "df_merged.drop(df_merged.loc[df_merged['SCORE']=='PEND'].index, inplace=True)\n",
    "\n",
    "# Update the SCORE column type to be integers so it is a numerical column:\n",
    "df_merged['SCORE'] = df_merged['SCORE'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not that our data is ready we can move on with our hypothesis test. We will use an ANOVA test here since we are looking at multiple different groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               sum_sq      df         F    PR(>F)\n",
      "C(neighborhood)           1934.925964    20.0  1.397902  0.111294\n",
      "C(price_value)            1333.055664     4.0  4.815383  0.000713\n",
      "C(CUISINE_DESCRIPTION)    6326.960270    74.0  1.235395  0.085385\n",
      "Residual                255516.637277  3692.0       NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "# Perform 2-sided ANOVA test. Use C() when working with categorical data\n",
    "formula2 = 'SCORE ~ C(neighborhood)+C(price_value)+C(CUISINE_DESCRIPTION)'\n",
    "lm2 = ols(formula2, df_merged).fit()\n",
    "result2 = sm.stats.anova_lm(lm2, typ=2)\n",
    "print(result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only the price has a p-value lower than .05 and therefore we can reject the null hypothesis and say the price has a relationship with the inspection score. However, for the neighborhood and cuisine type, neither seems to have an impact on the inspection score as its p-value is higher than .05, and therefore we fail to reject the null hypothesis.\n",
    "\n",
    "To understand which prices are statistically significant, we will run a Tukey HSD test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price vs. Score: \n",
      "    group1  group2  meandiff   p-adj   lower   upper  reject\n",
      "0       0       1   -1.0846  0.3290 -2.6602  0.4910   False\n",
      "1       0       2    0.2255  0.9000 -1.1455  1.5966   False\n",
      "2       0       3   -0.0002  0.9000 -1.6869  1.6865   False\n",
      "3       0       4   -2.0171  0.1299 -4.3613  0.3272   False\n",
      "4       1       2    1.3102  0.0047  0.2818  2.3385    True\n",
      "5       1       3    1.0844  0.2286 -0.3379  2.5067   False\n",
      "6       1       4   -0.9324  0.7373 -3.0943  1.2294   False\n",
      "7       2       3   -0.2257  0.9000 -1.4174  0.9659   False\n",
      "8       2       4   -2.2426  0.0206 -4.2602 -0.2250    True\n",
      "9       3       4   -2.0169  0.1019 -4.2610  0.2273   False\n"
     ]
    }
   ],
   "source": [
    "# Perform Tukey's HSD Test:\n",
    "mc2 = MultiComparison(df_merged['SCORE'], df_merged['price_value'])\n",
    "mc2_results = mc2.tukeyhsd()\n",
    "\n",
    "# Convert results to a dataframe\"\n",
    "tukey_data2 = pd.DataFrame(data=mc2_results._results_table.data[1:], columns = mc2_results._results_table.data[0])\n",
    "print(\"Price vs. Score:\",'\\n',tukey_data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these Tukey results we see that most prices do not generate statistically different inspection scores. However, the price range of 2 dollar signs does show statistical differences to both 1 dollar sign and 4 dollar signs. Next, I will calculate the effect size of each combination of prices that lead to us rejecting the null hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's d Chart:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price1</th>\n",
       "      <th>Price2</th>\n",
       "      <th>Cohen's d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.156453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.263009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Price1  Price2  Cohen's d\n",
       "0     1.0     2.0  -0.156453\n",
       "1     2.0     4.0   0.263009"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify the values we want to utilize to find Cohen's d:\n",
    "price_list = tukey_data2.loc[tukey_data2['reject']==True].iloc[:,:2].values.tolist()\n",
    "\n",
    "# Run function to see all Cohen's d values:\n",
    "print(\"Cohen's d Chart:\")\n",
    "multi_cohen_d(price_list, 'price_value', 'SCORE','Price1', 'Price2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In both cases the effect size is on the small side."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion:\n",
    "\n",
    "In summary, here are the results of our hypothesis test for each of our four questions:\n",
    "\n",
    "**1. Does a restaurant's Yelp rating influence how many Yelp reviews the restaurant will receive?**\n",
    "    <br>--> Reject Null Hypothesis, indicating a higher Yelp rating does lead to having a greate number of Yelp reviews received. However, the effect of this is very small.<br><br>\n",
    "**2. Does a restaurant's inspection grade influence how many Yelp reviews the restaurant will receive?**\n",
    "    <br>--> Reject Null Hypothesis, indicating having a higher inspection grade does lead to having a higher number of Yelp reviews received, though the effect size is small.<br><br>\n",
    "**3. Does the type of cuisine influence how many Yelp reviews the restaurant will receive?**\n",
    "    <br>--> Reject Null Hypothesis, indicating some cuisine types do impact the number of Yelp reviews received.<br><br>\n",
    "**4. Is there a relationship between the Inspection Grade and the Neighborhood, Price, or Cuisine Type?**\n",
    "    <br>--> Reject Null Hypothesis, as some price levels can have an impact on the inspection grade, such as when we look at 1 dollar sign vs. 2 dollar signs or 2 dollar signs vs. 4 dollar signs. However, we fail to reject the null hypothesis when looking specifically at the impact of the neighborhood or the cuisine type on inspection grade. <br><br>\n",
    "\n",
    "Based on these results, there are a few recommendations I would give to current or prospective restaurant owners:\n",
    "- Consider a 4 dollar sign price level rather than a 2 dollar sign price level as these types of restaurants often receive better inspection grades. \n",
    "- Ensure your restaurant is up to code and has minimal violations so that you are more likely to receive a better inspection grade, which likely will lead to a greater number of Yelp reviews, which in turn can draw more customers into your restaurant.\n",
    "- Ensure customers have an enjoyable experience at your restaurant so that they will not only give a high Yelp rating, but will also leave a positive review which can encourage other potential customers to try your restaurant.\n",
    "- When trying to ensure a strong inspection grade, cuisine type and neighborhood do not play a significant factor, so no limitations need to be considered in respect to these two aspects.\n",
    "\n",
    "# Next Steps:\n",
    "A few things to look into next:\n",
    "- Does the price impact the number of Yelp reviews?\n",
    "- Does having a critical violation impact the number of Yelp reviews or the inspection grade?\n",
    "- Do certain neighborhoods have significantly higher Yelp ratings?\n",
    "- Do certain neighborhoods have significantly higher inspection grades?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
